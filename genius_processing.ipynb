{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANITY CHECK - Search for a song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Welcome to New York by Taylor Swift\n",
      "Genius URL: https://genius.com/Taylor-swift-welcome-to-new-york-lyrics\n",
      "\n",
      "Title: ​portorosso’s DISCONTINUED 2023 Listening Log by still-life starlet\n",
      "Genius URL: https://genius.com/Still-life-starlet-portorossos-discontinued-2023-listening-log-annotated\n",
      "\n",
      "Title: ​youth group - background music by Josiah Botting\n",
      "Genius URL: https://genius.com/Josiah-botting-youth-group-background-music-annotated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Token from Genius API\n",
    "access_token = \"ULcds9ErDkTAQR14A6TzBFdaTfP-TGTZKtqGp1Bzk0Bam7IoftmGEysS_xm3sXYF\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\"\n",
    "}\n",
    "\n",
    "def search_song(query):\n",
    "    base_url = \"https://api.genius.com\"\n",
    "    search_url = f\"{base_url}/search\"\n",
    "    params = {\"q\": query}\n",
    "    response = requests.get(search_url, params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Search for a song\n",
    "results = search_song(\"Welcome to New York Taylor Swift\")\n",
    "\n",
    "# Print first few results\n",
    "for hit in results[\"response\"][\"hits\"][:3]:\n",
    "    print(\"Title:\", hit[\"result\"][\"full_title\"])\n",
    "    print(\"Genius URL:\", hit[\"result\"][\"url\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Lambda Function Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# SQS setup\n",
    "sqs = boto3.client('sqs')\n",
    "queue_name = 'genius-queue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQS queue created: https://sqs.us-east-1.amazonaws.com/654654514107/genius-queue\n"
     ]
    }
   ],
   "source": [
    "# create queue\n",
    "try:\n",
    "    response = sqs.create_queue(\n",
    "        QueueName=queue_name,\n",
    "        Attributes={\n",
    "            'VisibilityTimeout': '60'\n",
    "        }\n",
    "    )\n",
    "    queue_url = response['QueueUrl']\n",
    "    print(f\"SQS queue created: {queue_url}\")\n",
    "except sqs.exceptions.QueueNameExists:\n",
    "    queue_url = [url for url in sqs.list_queues()['QueueUrls'] if queue_name in url][0]\n",
    "    print(f\"SQS queue already exists: {queue_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy and connect lambda function\n",
    "lambda_client = boto3.client('lambda')\n",
    "iam = boto3.client('iam')\n",
    "sqs = boto3.client('sqs')\n",
    "\n",
    "function_name = 'genius_lambda'\n",
    "zip_path = 'genius_lambda.zip'\n",
    "sqs_queue_url = queue_url\n",
    "role = iam.get_role(RoleName='LabRole')['Role']['Arn']\n",
    "\n",
    "with open(zip_path, 'rb') as f:\n",
    "    zipped_code = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda function created!\n"
     ]
    }
   ],
   "source": [
    "# create lambda function\n",
    "try:\n",
    "    response = lambda_client.create_function(\n",
    "        FunctionName=function_name,\n",
    "        Runtime='python3.9',\n",
    "        Role=role,\n",
    "        Handler='lambda_function.lambda_handler',\n",
    "        Code={'ZipFile': zipped_code},\n",
    "        Timeout=10\n",
    "    )\n",
    "    print(\"lambda function created!\")\n",
    "except lambda_client.exceptions.ResourceConflictException:\n",
    "    print(\"lambda function already exists\")\n",
    "    response = lambda_client.update_function_code(\n",
    "        FunctionName=function_name,\n",
    "        ZipFile=zipped_code\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ARN for trigger\n",
    "sqs_attrs = sqs.get_queue_attributes(\n",
    "    QueueUrl=sqs_queue_url,\n",
    "    AttributeNames=['QueueArn']\n",
    ")\n",
    "sqs_arn = sqs_attrs['Attributes']['QueueArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedshiftEventSubscription\n",
      "RoleCreationFunction\n",
      "genius_lambda\n",
      "RedshiftOverwatch\n",
      "MainMonitoringFunction\n",
      "ModLabRole\n",
      "q1_lambda_function\n",
      "MACS30123_0424\n",
      "a2_1_lambda\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "lambda_client = boto3.client('lambda', region_name='us-east-1')  # Make sure you're in the correct region\n",
    "functions = lambda_client.list_functions()\n",
    "\n",
    "for f in functions['Functions']:\n",
    "    print(f['FunctionName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger already exists\n"
     ]
    }
   ],
   "source": [
    "# create SQS trigger\n",
    "try:\n",
    "    lambda_client.create_event_source_mapping(\n",
    "        EventSourceArn=sqs_arn,\n",
    "        FunctionName=function_name,\n",
    "        Enabled=True,\n",
    "        BatchSize=10\n",
    "    )\n",
    "    print(\"trigger creation successful\")\n",
    "except lambda_client.exceptions.ResourceConflictException:\n",
    "    print(\"trigger already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Lambda Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable updated!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "lambda_client = boto3.client('lambda')\n",
    "function_name = 'genius_lambda'  # Replace with your actual Lambda function name\n",
    "\n",
    "response = lambda_client.update_function_configuration(\n",
    "    FunctionName=function_name,\n",
    "    Environment={\n",
    "        'Variables': {\n",
    "            'GENIUS_API_TOKEN': 'WQcICxVxX0LlqnCDFstnowelGCDLUDkHiThnFMHzY7RBybx6S2hu2jnsELsg9RPP'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Environment variable updated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent to SQS: 43842ffd-151c-4c68-8435-8ee8f9698768\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "sqs = boto3.client('sqs')\n",
    "queue_url = 'https://sqs.us-east-1.amazonaws.com/654654514107/genius-queue'\n",
    "\n",
    "message_body = {\n",
    "    \"track_id\": \"123\",\n",
    "    \"title\": \"Welcome to New York\",\n",
    "    \"artist\": \"Taylor Swift\"\n",
    "}\n",
    "\n",
    "response = sqs.send_message(\n",
    "    QueueUrl=queue_url,\n",
    "    MessageBody=json.dumps(message_body)\n",
    ")\n",
    "\n",
    "print(\"Message sent to SQS:\", response['MessageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyrics/123.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'genius-bucket-654654514107'\n",
    "\n",
    "response = s3.list_objects_v2(Bucket='genius-bucket-654654514107')\n",
    "for obj in response.get('Contents', []):\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms my entire pipeline is working end-to-end:\n",
    "- Lambda is being triggered by SQS\n",
    "- Lyrics are being scraped and stored in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Dask to clean and match data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load all lyrics into a Dask dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_options = {\n",
    "'client_kwargs': {\n",
    "        'region_name': 'us-east-1'\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>url</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Welcome to New York</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>https://genius.com/Taylor-swift-welcome-to-new...</td>\n",
       "      <td>Lyrics not found.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id                title        artist  \\\n",
       "0       123  Welcome to New York  Taylor Swift   \n",
       "\n",
       "                                                 url             lyrics  \n",
       "0  https://genius.com/Taylor-swift-welcome-to-new...  Lyrics not found.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_json(\n",
    "    's3://genius-bucket-654654514107/lyrics/*.json',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "@delayed\n",
    "def clean_lyrics(doc):\n",
    "    text = re.sub(r'[^\\w\\s]', '', doc.lower())\n",
    "    tokens = text.split()\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# apply to a Dask DataFrame\n",
    "df['clean_lyrics'] = df['lyrics'].apply(clean_lyrics, meta=('clean_lyrics', 'str'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = dd.read_csv('final_joined_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_id', 'title', 'artist', 'url', 'lyrics', 'clean_lyrics'], dtype='object')\n",
      "Index(['track_id', 'spotify_id', 'emotion', 'title', 'artist', 'id',\n",
      "       'acousticness', 'analysis_url', 'danceability', 'duration', 'energy',\n",
      "       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
      "       'speechiness', 'tempo', 'time_signature', 'valence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(csv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_id', 'title', 'artist'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "csv_subset = csv_df[['track_id', 'title', 'artist']]\n",
    "print(csv_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_id_x', 'title', 'artist', 'url', 'lyrics', 'clean_lyrics',\n",
      "       'track_id_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "merged = df.merge(csv_subset, on=['title', 'artist'], how='inner')\n",
    "print(merged.columns)  # <- check here if 'track_id' is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'track_id_y' (Spotify's ID) to just 'track_id'\n",
    "merged = merged.rename(columns={'track_id_y': 'track_id'})\n",
    "\n",
    "# Select the columns you want to retain\n",
    "merged = merged[['track_id', 'title', 'artist', 'clean_lyrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Truth of Delayed objects is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/dask/dataframe/dask_expr/_collection.py:692\u001b[0m, in \u001b[0;36mFrameBase.head\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m    690\u001b[0m out \u001b[38;5;241m=\u001b[39m new_collection(expr\u001b[38;5;241m.\u001b[39mHead(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39mn, npartitions\u001b[38;5;241m=\u001b[39mnpartitions))\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m--> 692\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/dask/base.py:373\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/dask/base.py:681\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m     expr \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m    679\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(flatten(expr\u001b[38;5;241m.\u001b[39m__dask_keys__()))\n\u001b[0;32m--> 681\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(expr, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "File \u001b[0;32mlib.pyx:1241\u001b[0m, in \u001b[0;36mpandas._libs.lib.is_list_like\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mlib.pyx:1259\u001b[0m, in \u001b[0;36mpandas._libs.lib.c_is_list_like\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/dask/delayed.py:789\u001b[0m, in \u001b[0;36mDelayed.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruth of Delayed objects is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Truth of Delayed objects is not supported"
     ]
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit\n",
    "edit "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
